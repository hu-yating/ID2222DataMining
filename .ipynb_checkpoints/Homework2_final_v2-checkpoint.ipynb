{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handled-spirituality",
   "metadata": {},
   "source": [
    "# Discovery of Frequent Itemsets and Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-school",
   "metadata": {},
   "source": [
    "The problem of discovering association rules between itemsets in a sales transaction database (a set of baskets) includes the following two sub-problems:\n",
    "\n",
    "1. Finding frequent itemsets with support at least s;\n",
    "2. Generating association rules with confidence at least c from the itemsets found in the first step.\n",
    "Remind that an association rule is an implication X → Y, where X and Y are itemsets such that X∩Y=∅. Support of the rule X → Y is the number of transactions that contain X⋃Y. Confidence of the rule X → Y the fraction of transactions containing X⋃Y in all transactions that contain X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-carbon",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "You are to solve the first sub-problem: to implement the A-Priori algorithm for finding frequent itemsets with support at least s in a dataset of sales transactions. Remind that support of an itemset is the number of transactions containing the itemset. To test and evaluate your implementation, write a program that uses your A-Priori algorithm implementation to discover frequent itemsets with support at least s in a given dataset of sales transactions including generated transactions (baskets) of hashed items (see Canvas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "seven-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = [i.strip().split() for i in open(\"T10I4D100K.dat\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "liked-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = {} # Dictionary with basket ID as key, and basket as value\n",
    "count = 0\n",
    "for basket in baskets:\n",
    "    count += 1\n",
    "    transactions[count] = basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "associate-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = set() # Set of items from all baskets\n",
    "for i in transactions.values():\n",
    "    for j in i:\n",
    "        items.add(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "presidential-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each item\n",
    "def freq(k, items, transactions):\n",
    "    items_counts = dict() # Dictionary of item and its frequency\n",
    "    for item in items:\n",
    "        if k == 1:\n",
    "            temp_i = {item}\n",
    "        else:\n",
    "            temp_i = set(item)\n",
    "            \n",
    "        for transaction in transactions.items(): # and basket\n",
    "            if temp_i.issubset(set(transaction[1])): # if item is in basket\n",
    "                if item in items_counts:\n",
    "                    items_counts[item] += 1 # if already spotted/already in item-freq dict, add 1 to count\n",
    "                else:\n",
    "                    items_counts[item] = 1 # if not spotted yet, set count to 1\n",
    "    return items_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a05306c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Candidates of len-k which are generated by combining itemsets from L_k-1 and L_1\n",
    "def C_k(k, d):\n",
    "    cand = []\n",
    "    for i in d.keys():\n",
    "        if k-1 == 1:\n",
    "            temp = {i}\n",
    "            combs = combinations(list(temp.union(set(d.keys()))), k) \n",
    "            cand = list(combs)\n",
    "\n",
    "        else:\n",
    "            temp = set(i)\n",
    "            for j in d.keys():\n",
    "                if len(temp.union({j}))==k:\n",
    "                    cand.append(tuple(temp.union({j})))\n",
    "    return cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e5d57698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generate_freq(s_min):\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    size = 1\n",
    "    print(f\"Checking for k={size}...\")\n",
    "    support_dict = freq(1, items, transactions) #1-itemset\n",
    "    L = {j[0]:j[1] for j in support_dict.items() if j[1]>=s_min}  #change constant to s_min\n",
    "    results.append(L)\n",
    "    prev_freq = L\n",
    "    \n",
    "    while True: \n",
    "        size+=1\n",
    "        print(f\"Checking for k={size}...\")\n",
    "        candidates = C_k(size, prev_freq)\n",
    "        support_dict_k = freq(size, candidates, transactions)\n",
    "        prev_freq = {j[0]:j[1] for j in support_dict_k.items() if j[1]>=s_min} #change constant to s_min\n",
    "        if len(prev_freq)!=0:\n",
    "            results.append(prev_freq)\n",
    "        else: # empty k-itemset found\n",
    "            break\n",
    "            \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "empirical-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for k=1...\n",
      "Checking for k=2...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-286-6b35dbcab299>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-285-7e8ba68afca9>\u001b[0m in \u001b[0;36mgenerate_freq\u001b[1;34m(s_min)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Checking for k={size}...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcandidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_k\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0msupport_dict_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mprev_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msupport_dict_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0ms_min\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m#change constant to s_min\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-238-a43027159c43>\u001b[0m in \u001b[0;36mfreq\u001b[1;34m(k, items, transactions)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# and basket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mtemp_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# if item is in basket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitems_counts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[0mitems_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m# if already spotted/already in item-freq dict, add 1 to count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = generate_freq(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one dictionary\n",
    "total_dict = {k: v for d in results for k, v in d.items()}\n",
    "total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "tracked-recovery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['368',\n",
       " '829',\n",
       " '419',\n",
       " '217',\n",
       " '766',\n",
       " '684',\n",
       " '529',\n",
       " '354',\n",
       " '494',\n",
       " '722',\n",
       " ('529', '368'),\n",
       " ('529', '722'),\n",
       " ('529', '766'),\n",
       " ('529', '217'),\n",
       " ('529', '494'),\n",
       " ('529', '684'),\n",
       " ('529', '419'),\n",
       " ('529', '829'),\n",
       " ('529', '354'),\n",
       " ('368', '722'),\n",
       " ('368', '766'),\n",
       " ('368', '217'),\n",
       " ('368', '494'),\n",
       " ('368', '684'),\n",
       " ('368', '419'),\n",
       " ('368', '829'),\n",
       " ('368', '354'),\n",
       " ('722', '766'),\n",
       " ('722', '217'),\n",
       " ('722', '494'),\n",
       " ('722', '684'),\n",
       " ('722', '419'),\n",
       " ('722', '829'),\n",
       " ('722', '354'),\n",
       " ('766', '217'),\n",
       " ('766', '494'),\n",
       " ('766', '684'),\n",
       " ('766', '419'),\n",
       " ('766', '829'),\n",
       " ('766', '354'),\n",
       " ('217', '494'),\n",
       " ('217', '684'),\n",
       " ('217', '419'),\n",
       " ('217', '829'),\n",
       " ('217', '354'),\n",
       " ('494', '684'),\n",
       " ('494', '419'),\n",
       " ('494', '829'),\n",
       " ('494', '354'),\n",
       " ('684', '419'),\n",
       " ('684', '829'),\n",
       " ('684', '354'),\n",
       " ('419', '829'),\n",
       " ('419', '354'),\n",
       " ('829', '354')]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_itemsets = list(total_dict.keys())\n",
    "freq_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-packet",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Optional task for extra bonus: Solve the second sub-problem, i.e., develop and implement an algorithm for generating association rules between frequent itemsets discovered by using the A-Priori algorithm in a dataset of sales transactions. The rules must have support at least s and confidence at least c, where s and c are given as input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "offensive-psychiatry",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For every subset A of frequent itemset I, rule is A -> I\\A\n",
    "def association_rules():\n",
    "    rules = []\n",
    "    for itemset in list(results[-1].keys()): # First generate rules for the largest itemsets\n",
    "        rule = {}\n",
    "        for i in range(len(itemset)):\n",
    "            lhs = itemset[i]\n",
    "            rhs = set(itemset) - {lhs}\n",
    "            rule[lhs] = list(rhs)\n",
    "        rules.append(rule)\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ancient-deposit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'529': ['368'], '368': ['529']},\n",
       " {'529': ['722'], '722': ['529']},\n",
       " {'529': ['766'], '766': ['529']},\n",
       " {'529': ['217'], '217': ['529']},\n",
       " {'529': ['494'], '494': ['529']},\n",
       " {'529': ['684'], '684': ['529']},\n",
       " {'529': ['419'], '419': ['529']},\n",
       " {'529': ['829'], '829': ['529']},\n",
       " {'529': ['354'], '354': ['529']},\n",
       " {'368': ['722'], '722': ['368']},\n",
       " {'368': ['766'], '766': ['368']},\n",
       " {'368': ['217'], '217': ['368']},\n",
       " {'368': ['494'], '494': ['368']},\n",
       " {'368': ['684'], '684': ['368']},\n",
       " {'368': ['419'], '419': ['368']},\n",
       " {'368': ['829'], '829': ['368']},\n",
       " {'368': ['354'], '354': ['368']},\n",
       " {'722': ['766'], '766': ['722']},\n",
       " {'722': ['217'], '217': ['722']},\n",
       " {'722': ['494'], '494': ['722']},\n",
       " {'722': ['684'], '684': ['722']},\n",
       " {'722': ['419'], '419': ['722']},\n",
       " {'722': ['829'], '829': ['722']},\n",
       " {'722': ['354'], '354': ['722']},\n",
       " {'766': ['217'], '217': ['766']},\n",
       " {'766': ['494'], '494': ['766']},\n",
       " {'766': ['684'], '684': ['766']},\n",
       " {'766': ['419'], '419': ['766']},\n",
       " {'766': ['829'], '829': ['766']},\n",
       " {'766': ['354'], '354': ['766']},\n",
       " {'217': ['494'], '494': ['217']},\n",
       " {'217': ['684'], '684': ['217']},\n",
       " {'217': ['419'], '419': ['217']},\n",
       " {'217': ['829'], '829': ['217']},\n",
       " {'217': ['354'], '354': ['217']},\n",
       " {'494': ['684'], '684': ['494']},\n",
       " {'494': ['419'], '419': ['494']},\n",
       " {'494': ['829'], '829': ['494']},\n",
       " {'494': ['354'], '354': ['494']},\n",
       " {'684': ['419'], '419': ['684']},\n",
       " {'684': ['829'], '829': ['684']},\n",
       " {'684': ['354'], '354': ['684']},\n",
       " {'419': ['829'], '829': ['419']},\n",
       " {'419': ['354'], '354': ['419']},\n",
       " {'829': ['354'], '354': ['829']}]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "association_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "pressed-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one dictionary\n",
    "total_dict = {k: v for d in results for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "agreed-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check support of the rule, check support of lhs\n",
    "# To check confidence of the rule, divide {support of lhs} by {support of lhs and rhs combined}\n",
    "\n",
    "def calculate_confidence(min_c):\n",
    "    confidences = {}\n",
    "    for i in range(len(rules)):\n",
    "        rule = rules[i]\n",
    "        for lhs,rhs in zip(list(rule.keys()),list(rule.values())):\n",
    "            support = total_dict[lhs]\n",
    "            if tuple([lhs])+tuple(rhs) in total_dict:\n",
    "                confidence = total_dict[lhs]/total_dict[tuple([lhs])+tuple(rhs)]\n",
    "            if tuple(rhs)+tuple([lhs]) in total_dict:\n",
    "                confidence = total_dict[lhs]/total_dict[tuple(rhs)+tuple([lhs])]\n",
    "            confidences[str(lhs)+\"->\"+str(rhs)] = round(confidence,3)\n",
    "    association_rules_at_least_c = {j[0]:j[1] for j in confidences.items() if j[1]>=min_c}\n",
    "    return association_rules_at_least_c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "expanded-personal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"529->['722']\": 24.936,\n",
       " \"722->['529']\": 20.654,\n",
       " \"529->['766']\": 22.262,\n",
       " \"529->['494']\": 31.364,\n",
       " \"494->['529']\": 22.676,\n",
       " \"529->['684']\": 21.129,\n",
       " \"529->['419']\": 28.004,\n",
       " \"419->['529']\": 20.067,\n",
       " \"529->['354']\": 23.445,\n",
       " \"368->['217']\": 25.835,\n",
       " \"368->['684']\": 20.227,\n",
       " \"368->['419']\": 22.051,\n",
       " \"368->['354']\": 24.539,\n",
       " \"722->['494']\": 25.863,\n",
       " \"494->['722']\": 22.575,\n",
       " \"829->['722']\": 23.163,\n",
       " \"766->['217']\": 22.699,\n",
       " \"766->['494']\": 27.599,\n",
       " \"494->['766']\": 22.476,\n",
       " \"766->['419']\": 26.324,\n",
       " \"419->['766']\": 21.248,\n",
       " \"829->['766']\": 21.215,\n",
       " \"217->['494']\": 29.372,\n",
       " \"494->['217']\": 27.88,\n",
       " \"217->['684']\": 27.146,\n",
       " \"684->['217']\": 27.313,\n",
       " \"829->['217']\": 24.764,\n",
       " \"354->['217']\": 20.839,\n",
       " \"494->['684']\": 24.529,\n",
       " \"684->['494']\": 26.0,\n",
       " \"494->['419']\": 28.989,\n",
       " \"419->['494']\": 28.733,\n",
       " \"829->['494']\": 25.506,\n",
       " \"494->['354']\": 26.995,\n",
       " \"354->['494']\": 30.873,\n",
       " \"684->['419']\": 34.89,\n",
       " \"419->['684']\": 32.626,\n",
       " \"684->['354']\": 24.694,\n",
       " \"354->['684']\": 26.644,\n",
       " \"829->['419']\": 26.293,\n",
       " \"354->['419']\": 22.186,\n",
       " \"829->['354']\": 26.293,\n",
       " \"354->['829']\": 22.529}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_confidence(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-notification",
   "metadata": {},
   "source": [
    "### Try ouy for larger itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "inappropriate-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('368', '829', '419', '567'),\n",
       " ('368', '829', '419', '899'),\n",
       " ('368', '829', '567', '899'),\n",
       " ('368', '419', '567', '899'),\n",
       " ('829', '419', '567', '899')]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_items_4 = list(combinations(['368','829','419','567','899'],4))\n",
    "freq_items_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "excellent-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since conf(ABC → D) ≥ conf(AB →CD) ≥ conf(A → BCD), it's more efficient to find association rules with large lhs\n",
    "def association_rules(itemsets):\n",
    "    rules = []\n",
    "    for itemset in itemsets: # First generate rules for the largest itemsets\n",
    "        rule = {}\n",
    "        for i in range(len(itemset)):\n",
    "            rhs = itemset[i]\n",
    "            lhs = set(itemset) - {rhs}\n",
    "            rule[tuple(lhs)] = rhs\n",
    "        rules.append(rule)\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "olive-source",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('829', '419', '567'): '368',\n",
       "  ('419', '368', '567'): '829',\n",
       "  ('829', '368', '567'): '419',\n",
       "  ('829', '368', '419'): '567'},\n",
       " {('829', '899', '419'): '368',\n",
       "  ('368', '899', '419'): '829',\n",
       "  ('368', '829', '899'): '419',\n",
       "  ('829', '368', '419'): '899'},\n",
       " {('829', '899', '567'): '368',\n",
       "  ('368', '899', '567'): '829',\n",
       "  ('368', '829', '899'): '567',\n",
       "  ('829', '368', '567'): '899'},\n",
       " {('419', '899', '567'): '368',\n",
       "  ('368', '899', '567'): '419',\n",
       "  ('368', '899', '419'): '567',\n",
       "  ('419', '368', '567'): '899'},\n",
       " {('419', '899', '567'): '829',\n",
       "  ('829', '899', '567'): '419',\n",
       "  ('829', '899', '419'): '567',\n",
       "  ('829', '419', '567'): '899'}]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "association_rules(freq_items_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-camel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
